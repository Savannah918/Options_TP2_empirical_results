{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5773a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-28T00:00:00.000000000 finished\n",
      "2022-02-28T00:00:00.000000000 finished\n"
     ]
    }
   ],
   "source": [
    "#!/user/xt2276/.conda/envs/optionEnv/bin/python\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from itertools import product, permutations\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import root\n",
    "\n",
    "def get_forward_price(date, exdate, am_settlement):\n",
    "\n",
    "    with open(\"./2020_2023_forward_price_dict.pkl\", 'rb') as f:\n",
    "        fp_dict = pickle.load(f)\n",
    "    \n",
    "    return fp_dict[(date, exdate, am_settlement)]\n",
    "\n",
    "\n",
    "def preprocessing(df, am_settlement=1):\n",
    "    df = df[df['am_settlement'] == am_settlement]\n",
    "    # Assuming df is your DataFrame, 'strike_price' and 'maturity_date' are the columns of interest\n",
    "\n",
    "    # First, ensure that 'strike_price' and 'maturity_date' are the appropriate types (if they're not already)\n",
    "    df['strike_price'] = df['strike_price'].astype(float)\n",
    "    df['exdate'] = pd.to_datetime(df['exdate'])\n",
    "\n",
    "    # Create the dictionary for 'strike_price'\n",
    "    strike_price_dict = df.groupby('strike_price').apply(lambda x: x.index.tolist()).to_dict()\n",
    "\n",
    "    # Sort the dictionary by key (i.e., strike price)\n",
    "    strike_price_dict = OrderedDict(sorted(strike_price_dict.items()))\n",
    "\n",
    "    # Create the dictionary for 'maturity_date'\n",
    "#     maturity_date_dict = df.groupby('exdate').apply(lambda x: x.index.tolist()).to_dict()\n",
    "\n",
    "    # Sort the dictionary by key (i.e., maturity date)\n",
    "#     maturity_date_dict = OrderedDict(sorted(maturity_date_dict.items()))\n",
    "\n",
    "    return strike_price_dict\n",
    "\n",
    "\n",
    "# ------------------------------- constructing price 4 tuple set------------------------\n",
    "#  this version has no constraint that K2 needs to be greater than K1\n",
    "\n",
    "def get_price_set(strike_price_dict):\n",
    "    #     perm_dict = {key: len(list(permutations(strike_price_dict[key], 2))) for key in strike_price_dict.keys()}\n",
    "    # Initialize an empty set to store the 4-tuples\n",
    "    s1 = set()\n",
    "\n",
    "    perm_dict = {key: list(permutations(strike_price_dict[key], 2)) for key in strike_price_dict.keys()}\n",
    "    # For each strike price group\n",
    "    keys_list = list(strike_price_dict.keys())\n",
    "\n",
    "    for i, key1 in enumerate(keys_list):\n",
    "        # Generate all combinations of 2 elements in this group\n",
    "        perm1 = perm_dict[key1]\n",
    "        for key2 in keys_list:  # Here, start from the key following key1\n",
    "            # Generate all permutations of 2 elements in this group\n",
    "            perm2 = perm_dict[key2]\n",
    "        \n",
    "            # Generate all ordered pairs of permutations from the two groups\n",
    "            for pair1 in perm1:\n",
    "                for pair2 in perm2:\n",
    "                    # Check conditions: r1's strike price = r4's strike price and r2's strike price = r3's strike price\n",
    "                    s1.add((pair1[0], pair2[0], pair2[1], pair1[1]))\n",
    "    return s1\n",
    "\n",
    "def index_to_symbol(df, four_tuples_set, cp_flag = 'C'):\n",
    "\n",
    "    data = []\n",
    "    for tup in four_tuples_set:\n",
    "        s1, s2, s3, s4 = tup\n",
    "        s1_prime = df.loc[s1, 'symbol']\n",
    "        s2_prime = df.loc[s2, 'symbol']\n",
    "        s3_prime = df.loc[s3, 'symbol']\n",
    "        s4_prime = df.loc[s4, 'symbol']\n",
    "\n",
    "        strike_prices = [df.loc[s, 'strike_price'] for s in [s1, s2, s3, s4]]\n",
    "        forward_prices = [df.loc[s, 'forward_price'] for s in [s1, s2, s3, s4]]\n",
    "        maturity_dates = [df.loc[s, 'exdate'] for s in [s1, s2, s3, s4]]\n",
    "        s1_mid = (df.loc[s1, 'best_bid'] + df.loc[s1, 'best_offer']) / 2\n",
    "        s2_mid = (df.loc[s2, 'best_bid'] + df.loc[s2, 'best_offer']) / 2\n",
    "        s3_mid = (df.loc[s3, 'best_bid'] + df.loc[s3, 'best_offer']) / 2\n",
    "        s4_mid = (df.loc[s4, 'best_bid'] + df.loc[s4, 'best_offer']) / 2\n",
    "        mid_prices = [s1_mid, s2_mid, s3_mid, s4_mid]\n",
    "        \n",
    "        violation_magnitude = 0\n",
    "        validate = True\n",
    "        validate_tol = True\n",
    "        if cp_flag == 'C':\n",
    "            if s1_mid * s2_mid < s4_mid * s3_mid:\n",
    "                violation_magnitude = s4_mid * s3_mid - s1_mid * s2_mid\n",
    "                validate = False\n",
    "                if df.loc[s1, 'best_offer'] * df.loc[s2, 'best_offer'] < df.loc[s4, 'best_bid'] * df.loc[s3, 'best_bid']:\n",
    "                    validate_tol = False\n",
    "        else:\n",
    "            if s1_mid * s2_mid > s4_mid * s3_mid:\n",
    "                violation_magnitude = s1_mid * s2_mid - s4_mid * s3_mid\n",
    "                validate = False\n",
    "                if df.loc[s1, 'best_bid'] * df.loc[s2, 'best_bid'] > df.loc[s4, 'best_offer'] * df.loc[s3, 'best_offer']:\n",
    "                    validate_tol = False\n",
    "\n",
    "        data.append(((s1_prime, s2_prime, s3_prime, s4_prime), validate, validate_tol, strike_prices, maturity_dates, mid_prices, violation_magnitude, forward_prices))\n",
    "\n",
    "    # Create the new DataFrame\n",
    "    new_df = pd.DataFrame(data, columns=[\"Index\", \"validate\", \"validate_tol\", \"Strike Prices\", \"Maturity Dates\", \"Mid Prices\", \"Violation Magnitude\", \"Forward Prices\"])\n",
    "    new_df.set_index(\"Index\", inplace=True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def generate_s3_indexed(dataset_name, start_date, end_date, vol=50, cp_flag = 'C', am_flag = 1):\n",
    "    # Read the main CSV file into a DataFrame\n",
    "    with open(f'./{dataset_name}', 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "#     df = pd.read_csv(dataset_name)\n",
    "    # print(len(df))\n",
    "    df = df[df['volume'] > vol]\n",
    "    df = df[df['cp_flag'] == cp_flag]\n",
    "    df = df[df['date'] >= start_date]\n",
    "    df = df[df['date'] < end_date]\n",
    "    df = df[df['am_settlement'] == am_flag]\n",
    "    \n",
    "    # Ensure that the date column is of type datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['exdate'] = pd.to_datetime(df['exdate'])\n",
    "\n",
    "    # Get a list of unique dates\n",
    "    dates = df['date'].unique()\n",
    "    \n",
    "    # Process the data for each date\n",
    "    for date in dates:\n",
    "        df_date = df[df['date'] == date]  # Filter the DataFrame to include only rows with the current date\n",
    "\n",
    "        strike_price_dict = preprocessing(df_date, am_settlement=am_flag)\n",
    "#         strike_price_dict, maturity_date_dict = preprocessing(df_date, am_settlement=0)\n",
    "\n",
    "        s1 = get_price_set(strike_price_dict)\n",
    "        \n",
    "#         Enforce that 1<=K1/F_T1 <= K2/F_T2\n",
    "        s2 = set()\n",
    "        for s in s1:\n",
    "            (a,b,c,d) = s\n",
    "#             if cp_flag == 'C':\n",
    "#                 print((df_date.loc[a,\"strike_price\"], df_date.loc[a,\"forward_price\"])) (4275000, 4317.775429)\n",
    "#                 if 1000 < (df_date.loc[a,\"strike_price\"]/df_date.loc[a,\"forward_price\"]) < (df_date.loc[b,\"strike_price\"]/df_date.loc[b,\"forward_price\"]):\n",
    "            if (df_date.loc[a,\"strike_price\"]/df_date.loc[a,\"forward_price\"]) < (df_date.loc[b,\"strike_price\"]/df_date.loc[b,\"forward_price\"]):\n",
    "                s2.add(s)\n",
    "        \n",
    "        s3 = set()\n",
    "        for s in s2:\n",
    "            (a,b,c,d) = s\n",
    "            if df_date.loc[a,\"exdate\"] == df_date.loc[c,\"exdate\"] and df_date.loc[b,\"exdate\"] == df_date.loc[d,\"exdate\"] and df_date.loc[a,\"exdate\"] < df_date.loc[b,\"exdate\"]:\n",
    "                s3.add(s)\n",
    "        print(f\"{date} finished\")\n",
    "        \n",
    "        \n",
    "#         original_df = pd.read_csv(dataset_name)\n",
    "        with open(f'./{dataset_name}', 'rb') as f:\n",
    "                original_df = pickle.load(f)\n",
    "        indexed_df = index_to_symbol(original_df, s3, cp_flag)\n",
    "        with open(f'./2022_Filtering_condition_3/{str(date)[:10]}FC3_indexed_{cp_flag}_am={str(am_flag)}_vol{str(vol)}_{dataset_name}.pkl', 'wb') as f:\n",
    "            pickle.dump(indexed_df, f)\n",
    "            \n",
    "def main():\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    generate_s3_indexed(dataset_name = '2022_with_forward_price.pkl', start_date = '2022-02-28', end_date = '2022-03-01', vol=50, cp_flag = 'C', am_flag = 0)\n",
    "    generate_s3_indexed(dataset_name = '2022_with_forward_price.pkl', start_date = '2022-02-28', end_date = '2022-03-01', vol=50, cp_flag = 'P', am_flag = 0)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c5cb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31T00:00:00.000000000 finished\n",
      "2022-10-31T00:00:00.000000000 finished\n"
     ]
    }
   ],
   "source": [
    "generate_s3_indexed(dataset_name = '2022_with_forward_price.pkl', start_date = '2022-10-31', end_date = '2022-11-01', vol=50, cp_flag = 'C', am_flag = 0)\n",
    "generate_s3_indexed(dataset_name = '2022_with_forward_price.pkl', start_date = '2022-10-31', end_date = '2022-11-01', vol=50, cp_flag = 'P', am_flag = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c68f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d86d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
